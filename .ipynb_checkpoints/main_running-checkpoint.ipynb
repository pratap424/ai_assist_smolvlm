{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44839c3b-620a-4aa7-9b68-c64b8cd31b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hp/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\hp/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 4 cars, 210.5ms\n",
      "Speed: 1.9ms preprocess, 210.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyttsx3\n",
    "\n",
    "from modules.yolo_module import YOLODetector\n",
    "from modules.midas_module import MiDaSDepth\n",
    "from modules.smolvlm_module import describe_image\n",
    "\n",
    "class VisionAssistTTS(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"AI Vision Assist with Navigation\")\n",
    "        self.geometry(\"900x600\")\n",
    "\n",
    "        # UI elements\n",
    "        self.btn_load = tk.Button(self, text=\"Load Image\", command=self.load_file)\n",
    "        self.btn_load.pack(pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self, width=640, height=360, bg=\"black\")\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.txt_info = tk.Text(self, wrap=\"word\", height=10)\n",
    "        self.txt_info.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "        # Models\n",
    "        self.yolo = YOLODetector()\n",
    "        self.midas = MiDaSDepth()\n",
    "        self.engine = pyttsx3.init()\n",
    "\n",
    "    def load_file(self):\n",
    "        path = filedialog.askopenfilename(\n",
    "            filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\"), (\"All files\", \"*.*\")]\n",
    "        )\n",
    "        if not path:\n",
    "            return\n",
    "\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.txt_info.delete(\"1.0\", tk.END)\n",
    "\n",
    "        self.process_image(path)\n",
    "\n",
    "    def speak(self, text):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def process_image(self, path):\n",
    "        img = Image.open(path).resize((640, 360))\n",
    "        self.photo = ImageTk.PhotoImage(img, master=self)\n",
    "        self.canvas.create_image(0, 0, anchor=\"nw\", image=self.photo)\n",
    "\n",
    "        # Run detection & depth\n",
    "        objects = self.yolo.detect(img)\n",
    "        depth_array, depth_vis = self.midas.estimate_depth(img)\n",
    "        caption = describe_image(path)\n",
    "\n",
    "        # Track object instances\n",
    "        summary = {}\n",
    "        distances = []\n",
    "\n",
    "        info = f\"Scene Summary:\\n{caption}\\n\\nObjects Summary:\\n\"\n",
    "        for obj in objects:\n",
    "            label = obj[\"label\"]\n",
    "            x1, y1, x2, y2 = obj[\"bbox\"]\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            distance = float(depth_array[cy, cx])\n",
    "            distances.append((label, (x1, y1, x2, y2), distance))\n",
    "            summary[label] = summary.get(label, 0) + 1\n",
    "\n",
    "        for k, v in summary.items():\n",
    "            info += f\" - {k}: {v}\\n\"\n",
    "\n",
    "        # Closest and farthest object\n",
    "        if distances:\n",
    "            closest = min(distances, key=lambda x: x[2])\n",
    "            farthest = max(distances, key=lambda x: x[2])\n",
    "            info += f\"\\nClosest Object:\\n - {closest[0]} at {closest[2]:.2f}m\\n\"\n",
    "            info += f\"Farthest Object:\\n - {farthest[0]} at {farthest[2]:.2f}m\\n\"\n",
    "\n",
    "            # Directional guidance (simple version)\n",
    "            center_x = (closest[1][0] + closest[1][2]) // 2\n",
    "            if center_x < 213:\n",
    "                direction = \"to your left\"\n",
    "            elif center_x < 426:\n",
    "                direction = \"straight ahead\"\n",
    "            else:\n",
    "                direction = \"to your right\"\n",
    "            nav_msg = f\"{closest[0].capitalize()} detected {direction}, about {closest[2]:.1f} meters away.\"\n",
    "            info += f\"\\nGuidance:\\n - {nav_msg}\"\n",
    "            self.speak(f\"{caption}. {nav_msg}.\")\n",
    "        else:\n",
    "            self.speak(caption)\n",
    "\n",
    "        self.txt_info.insert(tk.END, info)\n",
    "\n",
    "        # Show depth map\n",
    "        depth_win = tk.Toplevel(self)\n",
    "        depth_win.title(\"Depth Map\")\n",
    "        if isinstance(depth_vis, Image.Image):\n",
    "            dv_img = depth_vis.resize((320, 180))\n",
    "        else:\n",
    "            dv_img = Image.fromarray((depth_vis * 255).astype(np.uint8)).resize((320, 180))\n",
    "\n",
    "        dv_photo = ImageTk.PhotoImage(dv_img, master=depth_win)\n",
    "        lbl = tk.Label(depth_win, image=dv_photo)\n",
    "        lbl.image = dv_photo\n",
    "        lbl.pack()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = VisionAssistTTS()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a1fec81-ebe6-4d84-a7f8-dc9317c0f1b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_tkinter.tkapp' object has no attribute 'on_object_select'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtxt_info\u001b[38;5;241m.\u001b[39minsert(tk\u001b[38;5;241m.\u001b[39mEND, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo Description:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcaption\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(Depth/object detection not available for video)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mVisionApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     app\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[24], line 36\u001b[0m, in \u001b[0;36mVisionApp.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj_dropdown \u001b[38;5;241m=\u001b[39m ttk\u001b[38;5;241m.\u001b[39mCombobox(\u001b[38;5;28mself\u001b[39m, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj_dropdown\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj_dropdown\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<ComboboxSelected>>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_object_select\u001b[49m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Models and state\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myolo \u001b[38;5;241m=\u001b[39m YOLODetector()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\midas_env\\lib\\tkinter\\__init__.py:2354\u001b[0m, in \u001b[0;36mTk.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m   2352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[0;32m   2353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelegate attribute access to the interpreter object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_tkinter.tkapp' object has no attribute 'on_object_select'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import math\n",
    "\n",
    "from modules.yolo_module import YOLODetector\n",
    "from modules.midas_module import MiDaSDepth\n",
    "from modules.smolvlm_module import describe_image, describe_video, plan_navigation\n",
    "\n",
    "# Helper to compute left/center/right direction based on x-coordinate\n",
    "def compute_direction(cx, width):\n",
    "    if cx < width * 0.33:\n",
    "        return \"left\"\n",
    "    elif cx > width * 0.66:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"center\"\n",
    "\n",
    "class VisionApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"AI Vision Assistant - Basic Navigation\")\n",
    "        self.geometry(\"900x650\")\n",
    "\n",
    "        # UI Elements\n",
    "        tk.Button(self, text=\"Load Image/Video\", command=self.load_file).pack(pady=10)\n",
    "        self.canvas = tk.Canvas(self, width=640, height=360, bg=\"black\")\n",
    "        self.canvas.pack()\n",
    "        self.txt_info = tk.Text(self, wrap=\"word\", height=10)\n",
    "        self.txt_info.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        self.obj_dropdown = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.obj_dropdown.pack(pady=5)\n",
    "        self.obj_dropdown.bind(\"<<ComboboxSelected>>\", self.on_object_select)\n",
    "\n",
    "        # Models and state\n",
    "        self.yolo = YOLODetector()\n",
    "        self.midas = MiDaSDepth()\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.selected_image = None\n",
    "        self.depth_map = None\n",
    "        self.objects = []  # list of dicts {label, bbox}\n",
    "\n",
    "    def load_file(self):\n",
    "        path = filedialog.askopenfilename(\n",
    "            filetypes=[(\"Media files\", \"*.jpg *.jpeg *.png *.mp4 *.avi\"), (\"All files\", \"*.*\")]\n",
    "        )\n",
    "        if not path:\n",
    "            return\n",
    "        # Clear previous\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.txt_info.delete(\"1.0\", tk.END)\n",
    "        if path.lower().endswith((\".mp4\", \".avi\")):\n",
    "            self.process_video(path)\n",
    "        else:\n",
    "            self.process_image(path)\n",
    "\n",
    "    def process_image(self, path):\n",
    "        # Load and display image\n",
    "        img = Image.open(path).convert(\"RGB\").resize((640, 360))\n",
    "        self.selected_image = img.copy()\n",
    "        self.photo = ImageTk.PhotoImage(img, master=self)\n",
    "        self.canvas.create_image(0, 0, anchor='nw', image=self.photo)\n",
    "\n",
    "        # Run YOLO detection\n",
    "        detections = self.yolo.detect(img)\n",
    "        self.objects = [{\"label\": d['label'], \"bbox\": d['bbox']} for d in detections]\n",
    "\n",
    "        # Run MiDaS depth estimation\n",
    "        depth_arr, depth_vis = self.midas.estimate_depth(img)\n",
    "        self.depth_map = depth_arr\n",
    "\n",
    "        # Show depth map\n",
    "        depth_win = tk.Toplevel(self)\n",
    "        depth_win.title(\"Depth Map\")\n",
    "        if isinstance(depth_vis, Image.Image):\n",
    "            dv_img = depth_vis.resize((320, 180))\n",
    "        else:\n",
    "            dv_img = Image.fromarray((depth_vis * 255).astype(np.uint8)).resize((320, 180))\n",
    "        dv_photo = ImageTk.PhotoImage(dv_img, master=depth_win)\n",
    "        tk.Label(depth_win, image=dv_photo).pack()\n",
    "        depth_win.image = dv_photo\n",
    "\n",
    "        # Generate scene caption\n",
    "        caption = describe_image(path)\n",
    "        info = f\"Caption:\\n{caption}\\n\\nObjects Detected:\\n\"\n",
    "        for idx, obj in enumerate(self.objects):\n",
    "            info += f\"{idx}. {obj['label']} at {obj['bbox']}\\n\"\n",
    "        self.txt_info.insert(tk.END, info)\n",
    "\n",
    "        # Populate dropdown\n",
    "        labels = [f\"{obj['label']} ({i})\" for i, obj in enumerate(self.objects)]\n",
    "        self.obj_dropdown['values'] = labels\n",
    "        if labels:\n",
    "            self.obj_dropdown.set(labels[0])\n",
    "\n",
    "    def on_object_select(self, event):\n",
    "        idx = self.obj_dropdown.current()\n",
    "        if idx < 0 or idx >= len(self.objects) or self.depth_map is None:\n",
    "            return\n",
    "        obj = self.objects[idx]\n",
    "        label = obj['label']\n",
    "        x1, y1, x2, y2 = obj['bbox']\n",
    "\n",
    "        # Compute center pixel of object\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        h, w = self.depth_map.shape\n",
    "        cx = max(0, min(cx, w-1))\n",
    "        cy = max(0, min(cy, h-1))\n",
    "\n",
    "        # Get distance (relative units)\n",
    "        dist = round(float(self.depth_map[cy, cx]), 2)\n",
    "        direction = compute_direction(cx, w)\n",
    "\n",
    "        # Check for obstacle in center corridor (40%-60% width)\n",
    "        warning = \"\"\n",
    "        left_bound = w * 0.4\n",
    "        right_bound = w * 0.6\n",
    "        for other in self.objects:\n",
    "            if other is obj:\n",
    "                continue\n",
    "            ox1, oy1, ox2, oy2 = other['bbox']\n",
    "            ocx = (ox1 + ox2) // 2\n",
    "            ocy = (oy1 + oy2) // 2\n",
    "            od = float(self.depth_map[max(0, min(ocy, h-1)), max(0, min(ocx, w-1))])\n",
    "            if od < dist and left_bound < ocx < right_bound:\n",
    "                # Obstacle directly ahead\n",
    "                side = 'left' if ocx > w/2 else 'right'\n",
    "                warning = f\"Obstacle ({other['label']}) {round(od,2)}m ahead. Step {side} 0.5m, then move forward.\"\n",
    "                break\n",
    "\n",
    "        # Build instruction\n",
    "        if warning:\n",
    "            instruction = warning + f\" Then the {label} is {dist} units away to your {direction}.\"\n",
    "        else:\n",
    "            instruction = f\"The {label} is {dist} units away to your {direction}.\"\n",
    "\n",
    "        # Show and speak\n",
    "        self.txt_info.insert(tk.END, f\"\\nNavigation:\\n{instruction}\\n\")\n",
    "        self.tts.say(instruction)\n",
    "        self.tts.runAndWait()\n",
    "\n",
    "        # Highlight selected object\n",
    "        img_arr = np.array(self.selected_image)\n",
    "        cv2.rectangle(img_arr, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        disp = Image.fromarray(img_arr).resize((640, 360))\n",
    "        self.photo = ImageTk.PhotoImage(disp, master=self)\n",
    "        self.canvas.create_image(0, 0, anchor='nw', image=self.photo)\n",
    "\n",
    "    def process_video(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        if not ret:\n",
    "            messagebox.showerror(\"Error\", \"Cannot read video.\")\n",
    "            return\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame).resize((640, 360))\n",
    "        self.photo = ImageTk.PhotoImage(img, master=self)\n",
    "        self.canvas.create_image(0, 0, anchor='nw', image=self.photo)\n",
    "        caption = describe_video(path)\n",
    "        self.txt_info.insert(tk.END, f\"Video Description:\\n{caption}\\n(Depth/object detection not available for video)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = VisionApp()\n",
    "    app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba091234-f152-4e3f-a33b-b8b2af9ee445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hp/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\hp/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 8 persons, 1 backpack, 7 chairs, 1 couch, 1 tv, 2 laptops, 158.0ms\n",
      "Speed: 1.4ms preprocess, 158.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import math\n",
    "\n",
    "from modules.yolo_module import YOLODetector\n",
    "from modules.midas_module import MiDaSDepth\n",
    "from modules.smolvlm_module import describe_image, describe_video\n",
    "\n",
    "# Compute left/center/right based on x coordinate\n",
    "def compute_direction(cx, width):\n",
    "    if cx < width * 0.33:\n",
    "        return \"left\"\n",
    "    elif cx > width * 0.66:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"center\"\n",
    "\n",
    "class VisionApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"AI Vision Assistant - Guided Navigation\")\n",
    "        self.geometry(\"900x700\")\n",
    "\n",
    "        # UI\n",
    "        tk.Button(self, text=\"Load Image/Video\", command=self.load_file).pack(pady=10)\n",
    "        self.canvas = tk.Canvas(self, width=640, height=360, bg=\"black\")\n",
    "        self.canvas.pack()\n",
    "        self.txt_info = tk.Text(self, wrap=\"word\", height=12)\n",
    "        self.txt_info.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        self.obj_dropdown = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.obj_dropdown.pack(pady=5)\n",
    "        self.obj_dropdown.bind(\"<<ComboboxSelected>>\", self.on_object_select)\n",
    "\n",
    "        # Models & state\n",
    "        self.yolo = YOLODetector()\n",
    "        self.midas = MiDaSDepth()\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.selected_image = None\n",
    "        self.depth_map = None\n",
    "        self.landmarks = []  # each is dict with label, bbox, dist, cx, cy\n",
    "        self.scene_overview = \"\"\n",
    "\n",
    "    def load_file(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"Media files\",\"*.jpg *.jpeg *.png *.mp4 *.avi\"),(\"All\",\"*.*\")])\n",
    "        if not path: return\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.txt_info.delete(\"1.0\", tk.END)\n",
    "        self.process_image(path)\n",
    "\n",
    "    def process_image(self, path):\n",
    "        # display\n",
    "        img = Image.open(path).convert(\"RGB\").resize((640,360))\n",
    "        self.selected_image = img.copy()\n",
    "        self.photo = ImageTk.PhotoImage(img, master=self)\n",
    "        self.canvas.create_image(0,0,anchor='nw',image=self.photo)\n",
    "        \n",
    "        # YOLO + depth\n",
    "        raw = self.yolo.detect(img)\n",
    "        depth_arr, depth_vis = self.midas.estimate_depth(img)\n",
    "        self.depth_map = depth_arr\n",
    "        h,w = depth_arr.shape\n",
    "\n",
    "        # Scene overview from SMOL\n",
    "        self.scene_overview = describe_image(path)\n",
    "        self.txt_info.insert(tk.END, f\"Scene Overview:\\n{self.scene_overview}\\n\\n\")\n",
    "        self.tts.say(self.scene_overview)\n",
    "        self.tts.runAndWait()\n",
    "\n",
    "        # Build landmarks with geometry\n",
    "        self.landmarks = []\n",
    "        for idx,obj in enumerate(raw):\n",
    "            x1,y1,x2,y2 = map(int,obj['bbox'])\n",
    "            cx,cy = (x1+x2)//2,(y1+y2)//2\n",
    "            cx=np.clip(cx,0,w-1); cy=np.clip(cy,0,h-1)\n",
    "            dist=float(depth_arr[cy,cx])\n",
    "            self.landmarks.append({'label':obj['label'],'bbox':(x1,y1,x2,y2),'dist':round(dist,2),'cx':cx,'cy':cy})\n",
    "        # sort by distance\n",
    "        self.landmarks.sort(key=lambda o:o['dist'])\n",
    "\n",
    "        # list landmarks\n",
    "        self.txt_info.insert(tk.END,\"Landmarks (nearest first):\\n\")\n",
    "        for i, lm in enumerate(self.landmarks):\n",
    "            self.txt_info.insert(tk.END,f\"{i}. {lm['label']} at {lm['dist']} m\\n\")\n",
    "\n",
    "        # dropdown\n",
    "        vals=[f\"{lm['label']} ({i})\" for i,lm in enumerate(self.landmarks)]\n",
    "        self.obj_dropdown['values']=vals\n",
    "        if vals: self.obj_dropdown.set(vals[0])\n",
    "\n",
    "        # show depth map\n",
    "        depth_win=tk.Toplevel(self); depth_win.title(\"Depth Map\")\n",
    "        dv_img=depth_vis.resize((320,180)) if isinstance(depth_vis,Image.Image) else Image.fromarray((depth_vis*255).astype(np.uint8)).resize((320,180))\n",
    "        ph=ImageTk.PhotoImage(dv_img,master=depth_win); tk.Label(depth_win,image=ph).pack(); depth_win.image=ph\n",
    "\n",
    "    def on_object_select(self,event):\n",
    "        idx=self.obj_dropdown.current()\n",
    "        if idx<0 or idx>=len(self.landmarks): return\n",
    "        # generate path steps\n",
    "        steps=[]\n",
    "        current_angle=0.0\n",
    "        user_x, user_y=320,360  # bottom-center of image\n",
    "        # iterate through landmarks up to target\n",
    "        target=self.landmarks[idx]\n",
    "        path_lms=self.landmarks[:idx] + [target]\n",
    "        for lm in path_lms:\n",
    "            dx=lm['cx']-user_x; dy=user_y-lm['cy']\n",
    "            angle=math.degrees(math.atan2(dx,dy))\n",
    "            turn=angle-current_angle\n",
    "            if abs(turn)>10:\n",
    "                dirn='right' if turn>0 else 'left'\n",
    "                steps.append(f\"Turn {abs(int(turn))}° {dirn} to face the {lm['label']}\")\n",
    "                current_angle=angle\n",
    "            steps.append(f\"Walk forward {lm['dist']:.1f} meters until the {lm['label']}\")\n",
    "            # update user position roughly at lm\n",
    "            user_x,lm_x=lm['cx'],lm['dist']\n",
    "        # speak and show\n",
    "        self.txt_info.insert(tk.END,\"\\nNavigation Steps:\\n\")\n",
    "        for s in steps:\n",
    "            self.txt_info.insert(tk.END,s+\"\\n\")\n",
    "            self.tts.say(s)\n",
    "        self.tts.runAndWait()\n",
    "        # highlight\n",
    "        x1,y1,x2,y2=target['bbox']\n",
    "        arr=np.array(self.selected_image)\n",
    "        cv2.rectangle(arr,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "        disp=Image.fromarray(arr).resize((640,360))\n",
    "        self.photo=ImageTk.PhotoImage(disp,master=self)\n",
    "        self.canvas.create_image(0,0,anchor='nw',image=self.photo)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    app=VisionApp(); app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bbf8bf-ccc2-4498-a98d-370dbd1bfe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hp/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\hp/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 4 cars, 155.6ms\n",
      "Speed: 1.5ms preprocess, 155.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import math\n",
    "\n",
    "from modules.yolo_module import YOLODetector\n",
    "from modules.midas_module import MiDaSDepth\n",
    "from modules.smolvlm_module import describe_image, plan_navigation \n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def compute_direction(cx, width):\n",
    "    if cx < width * 0.33:\n",
    "        return \"left\"\n",
    "    elif cx > width * 0.66:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"center\"\n",
    "\n",
    "\n",
    "def build_geometry_steps(landmarks, target_idx):\n",
    "    steps = []\n",
    "    current_angle = 0.0\n",
    "    user_x, user_y = 320, 360  # assume user at bottom-center of image\n",
    "    path = landmarks[:target_idx] + [landmarks[target_idx]]\n",
    "\n",
    "    for lm in path:\n",
    "        dx = lm['cx'] - user_x\n",
    "        dy = user_y - lm['cy']\n",
    "        angle = math.degrees(math.atan2(dx, dy))\n",
    "        turn = angle - current_angle\n",
    "        if abs(turn) > 5:\n",
    "            dirn = 'right' if turn > 0 else 'left'\n",
    "            steps.append(f\"Turn {abs(int(turn))}° {dirn} to face the {lm['label']}\")\n",
    "            current_angle = angle\n",
    "        steps.append(f\"Walk forward {lm['dist']:.1f} meters to the {lm['label']}\")\n",
    "        user_x, user_y = lm['cx'], lm['cy']\n",
    "    return steps\n",
    "\n",
    "\n",
    "class VisionApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"AI Vision Assistant - Guided Navigation\")\n",
    "        self.geometry(\"900x700\")\n",
    "\n",
    "        # UI\n",
    "        tk.Button(self, text=\"Load Image/Video\", command=self.load_file).pack(pady=10)\n",
    "        self.canvas = tk.Canvas(self, width=640, height=360, bg=\"black\")\n",
    "        self.canvas.pack()\n",
    "        self.txt_info = tk.Text(self, wrap=\"word\", height=12)\n",
    "        self.txt_info.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        self.obj_dropdown = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.obj_dropdown.pack(pady=5)\n",
    "        self.obj_dropdown.bind(\"<<ComboboxSelected>>\", self.on_object_select)\n",
    "\n",
    "        # Models & state\n",
    "        self.yolo = YOLODetector()\n",
    "        self.midas = MiDaSDepth()\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.selected_image = None\n",
    "        self.depth_map = None\n",
    "        self.landmarks = []  # each is dict with label, bbox, dist, cx, cy\n",
    "        self.scene_overview = \"\"\n",
    "\n",
    "    def load_file(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"Media files\",\"*.jpg *.jpeg *.png *.mp4 *.avi\"),(\"All\",\"*.*\")])\n",
    "        if not path:\n",
    "            return\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.txt_info.delete(\"1.0\", tk.END)\n",
    "        self.process_image(path)\n",
    "\n",
    "    def process_image(self, path):\n",
    "        img = Image.open(path).convert(\"RGB\").resize((640, 360))\n",
    "        self.selected_image = img.copy()\n",
    "        self.photo = ImageTk.PhotoImage(img, master=self)\n",
    "        self.canvas.create_image(0, 0, anchor='nw', image=self.photo)\n",
    "\n",
    "        # YOLO + depth\n",
    "        raw = self.yolo.detect(img)\n",
    "        depth_arr, depth_vis = self.midas.estimate_depth(img)\n",
    "        self.depth_map = depth_arr\n",
    "        h, w = depth_arr.shape\n",
    "\n",
    "        # Scene overview\n",
    "        self.scene_overview = describe_image(path)\n",
    "        self.txt_info.insert(tk.END, f\"Scene Overview:\\n{self.scene_overview}\\n\\n\")\n",
    "        self.tts.say(self.scene_overview)\n",
    "        self.tts.runAndWait()\n",
    "\n",
    "        # Build landmarks\n",
    "        self.landmarks = []\n",
    "        for idx, obj in enumerate(raw):\n",
    "            x1, y1, x2, y2 = map(int, obj['bbox'])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            cx = np.clip(cx, 0, w - 1)\n",
    "            cy = np.clip(cy, 0, h - 1)\n",
    "            dist = float(depth_arr[cy, cx])\n",
    "            self.landmarks.append({\n",
    "                'label': obj['label'],\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'dist': round(dist, 2),\n",
    "                'cx': cx,\n",
    "                'cy': cy\n",
    "            })\n",
    "        self.landmarks.sort(key=lambda o: o['dist'])\n",
    "\n",
    "        # List landmarks\n",
    "        self.txt_info.insert(tk.END, \"Landmarks (nearest first):\\n\")\n",
    "        for i, lm in enumerate(self.landmarks):\n",
    "            self.txt_info.insert(tk.END, f\"{i}. {lm['label']} at {lm['dist']} m\\n\")\n",
    "\n",
    "        # Dropdown\n",
    "        vals = [f\"{lm['label']} ({i})\" for i, lm in enumerate(self.landmarks)]\n",
    "        self.obj_dropdown['values'] = vals\n",
    "        if vals:\n",
    "            self.obj_dropdown.set(vals[0])\n",
    "\n",
    "        # Depth map preview\n",
    "        depth_win = tk.Toplevel(self)\n",
    "        depth_win.title(\"Depth Map\")\n",
    "        if isinstance(depth_vis, Image.Image):\n",
    "            dv_img = depth_vis.resize((320, 180))\n",
    "        else:\n",
    "            dv_img = Image.fromarray((depth_vis * 255).astype(np.uint8)).resize((320, 180))\n",
    "        ph = ImageTk.PhotoImage(dv_img, master=depth_win)\n",
    "        tk.Label(depth_win, image=ph).pack()\n",
    "        depth_win.image = ph\n",
    "\n",
    "    def on_object_select(self, event):\n",
    "        idx = self.obj_dropdown.current()\n",
    "        if idx < 0 or idx >= len(self.landmarks):\n",
    "            return\n",
    "\n",
    "        geometry_steps = build_geometry_steps(self.landmarks, idx)\n",
    "\n",
    "        # Generate natural language from geometry steps\n",
    "        natural_instruction = plan_navigation(self.landmarks, idx, geometry_steps)\n",
    "\n",
    "\n",
    "\n",
    "        # Display and speak\n",
    "        self.txt_info.insert(tk.END, \"\\nNavigation Plan:\\n\")\n",
    "        self.txt_info.insert(tk.END, natural_instruction + \"\\n\")\n",
    "        self.tts.say(natural_instruction)\n",
    "        self.tts.runAndWait()\n",
    "\n",
    "        # Highlight target object\n",
    "        x1, y1, x2, y2 = self.landmarks[idx]['bbox']\n",
    "        arr = np.array(self.selected_image)\n",
    "        cv2.rectangle(arr, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        disp = Image.fromarray(arr).resize((640, 360))\n",
    "        self.photo = ImageTk.PhotoImage(disp, master=self)\n",
    "        self.canvas.create_image(0, 0, anchor='nw', image=self.photo)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = VisionApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3e886-33d7-4669-98ca-47083304f251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
