
 ğŸš€ An AI Powered Vision and Navigation Assistance System

A modular, real time deep learning system that transitions from basic scene understanding to depth aware intelligent navigation, integrating object detection, depth estimation, vision language models, and audio visual feedback to assist in perceiving, interpreting, and interacting with the environment.

   

 ğŸ“„ 1. Abstract / Invention Overview

This invention presents a multi phase, AI driven system designed for comprehensive visual environment understanding and intelligent navigation assistance. It synergistically combines real time object detection, scene summarization, depth estimation, and navigation planning to deliver both descriptive and actionable feedback.

Key Capabilities:
  Detect and describe what's seen in an image or video
  Answer questions about a visual scene
  Estimate spatial layout from 2D input
  Plan a navigable path and guide users via instructions

   

 ğŸ¯ 2. Problem Statement & Background

Existing visual assistive tools offer limited, disconnected features. Most fail to:
  Integrate spatial understanding with scene interpretation
  Offer navigation guidance using real time environmental data

 â—This project solves that by:
  Combining visual recognition + spatial modeling
  Supporting both passive understanding (captions, Q&A) and active assistance (pathfinding, guidance)
  Building a modular and extensible system for various applications

   

 ğŸ”§ 3. System Overview

The system is built in two evolutionary phases, each enhancing capabilities:

   

 âœ… Phase 1(Earlier One) â€“ Foundational Visual Intelligence

| Feature                     | Description                                                                 |
|                            |                                                                             |
| ğŸŸ¨ Object Detection         | Uses `YOLOv8n` for identifying objects with bounding boxes & confidence     |
| ğŸ–¼ï¸ Scene Description        | `Salesforce BLIP` generates captions for images                             |
| ğŸï¸ Video Summarization     | BLIP processes keyframes and generates a coherent summary                   |
| â“ Visual Question Answering| BLIP VQA answers natural language questions about a visual input            |
| ğŸ–±ï¸ Interactive GUI         | `Tkinter` based GUI for loading/capturing media and showing outputs         |

   

 âœ… Phase 2(This one) â€“ Advanced Spatial Awareness & Navigation

| Feature                      | Description                                                                 |
|                             |                                                                             |
| ğŸ” Upgraded Object Detection | `YOLOv8l` for higher accuracy and better feature extraction                 |
| ğŸŒŠ Depth Estimation         | `MiDaS DPT_Large` estimates distance to scene elements from single image    |
| ğŸ—ºï¸ 2D Environment Grid      | Converts camera + depth input into a grid with free space and obstacles     |
| ğŸ§­ Pathfinding               | `A Algorithm` computes shortest path to chosen object                     |
| ğŸ”Š Audio Feedback            | Uses `pyttsx3` for offline TTS instructions                                |
| ğŸ–¼ï¸ SmolVLM Scene Summary    | `SmolVLM2` generates high quality image/video descriptions and instructions |
| ğŸ“Ÿ Navigation GUI           | Displays real time feed, depth map, grid with planned path, and feedback   |

   

 ğŸ“‚ 4. Codebase Breakdown



.
â”œâ”€â”€ smolvlm\_module.py        Scene/video captioning, navigation via SmolVLM
â”œâ”€â”€ yolo\_module.py           YOLOv8 object detection with bbox + confidence
â”œâ”€â”€ midas\_module.py          Monocular depth estimation (MiDaS)
â”œâ”€â”€ qna\_module.py            Context aware QnA with Sentence Transformers

`

   

 ğŸ” `yolo_module.py`
  Uses `ultralytics/yolov8l.pt`
  Outputs object label, bounding box, and confidence
python
detector = YOLODetector()
detections = detector.detect("img.jpg")
`

   

 ğŸ§  `smolvlm_module.py`

 Describes images/videos using SmolVLM2
 Plans natural language navigation using labeled detections and positions

python
describe_image("img.jpg")
describe_video("video.mp4")
plan_navigation(detections, target_index=0)


   

 ğŸŒŠ `midas_module.py`

 Estimates depth using `MiDaS DPT_Large`
 Returns numeric depth map and grayscale visualization

python
depth_model = MiDaSDepth()
depth_map, depth_img = depth_model.estimate_depth(pil_image)


   

 â“ `qna_module.py`

 Uses `SentenceTransformer (MiniLM)` for contextual QnA
 Accepts any scene description and allows relevant Q\&A

python
qna = QnASystem()
qna.update_context("A man is standing near a car...")
qna.answer_question("What is the man doing?")


   

 ğŸ› ï¸ 5. Technologies & Methodologies

| Category                   | Tools / Models                                                         |
|                            |                                                                        |
| ğŸ‘ï¸ Object Detection       | YOLOv8n (Phase 1), YOLOv8l (Phase 2)                                   |
| ğŸ–¼ï¸ Vision Language Models | Salesforce BLIP (Captioning, VQA), SmolVLM2 (Image/Video + Navigation) |
| ğŸŒŠ Depth Estimation        | MiDaS DPT\_Large (from Intel ISL)                                      |
| ğŸ” Pathfinding             | A\ Search Algorithm                                                   |
| ğŸ› ï¸ Programming Stack      | Python, PyTorch, Hugging Face, OpenCV, Tkinter, PIL, NumPy             |
| ğŸ”Š TTS                     | pyttsx3 for offline audio output                                       |
| â“ QnA Embeddings           | SentenceTransformers (all MiniLM L6 v2)                                |

   

 ğŸ’¡ 6. Potential Applications

 ğŸ§‘â€ğŸ¦¯ Assistive navigation for visually impaired individuals
 ğŸš Autonomous drones with spatial awareness
 ğŸ§  Vision language research in robotics
 ğŸ§­ Smart surveillance with scene understanding
 ğŸ“ Educational tools using QnA on visual data
 ğŸ“± Augmented reality systems for enhanced perception

   

 ğŸ Key Achievements

 âœ”ï¸ Full stack AI integration: detection + VLMs + navigation
 âœ”ï¸ Real time depth aware navigation with pathfinding
 âœ”ï¸ GUI based interface for interaction and control
 âœ”ï¸ Modular, expandable architecture for future upgrades

   

 ğŸ“¥ Installation

bash
pip install torch torchvision torchaudio
pip install ultralytics
pip install transformers
pip install sentence transformers
pip install opencv python
pip install decord
pip install pyttsx3

https://github.com/user-attachments/assets/51f320ad-c562-40ae-b757-6674f3705a12



